1. 深度生成模型概述
2. Hopfield神经网络
3. 玻尔兹曼机和受限玻尔兹曼机
4. 深度玻尔兹曼机和深度信念网络
5. 自编码器及其变种



# 深度生成模型概述

<img src="./PIC/11/11.1.png" alt="11.1" style="zoom:50%;" />

<img src="./PIC/11/11.2.png" alt="11.2" style="zoom:50%;" />

| 年份 | 事件                                                         | 相关论文                                                     |
| :--: | :----------------------------------------------------------- | ------------------------------------------------------------ |
| 1982 | Hopfield网络提出                                             | J. J . Hopfield . Neural networks and physical systems with emergent collective computational abilities. Proceedings of the National Academy of Sciences, Vol. 79 , No. 8, pp. 2554-2558, 1982 |
| 1983 | 玻尔兹曼机生成模型被提出                                     | Fahlman, S. E., Hinton, G. E., & Sejnowski, T. J. (1983). Massively parallel architectures for Al: NETL, Thistle, and Boltzmann machines. Proceedings of AAAI-83109, 113 |
| 1992 | Neal提出了sigmoid信念网 络                                   | Neal, R. M. (1992). Connectionist learning of belief networks. Artificial intelligence, 56(1), 71- 113 |
| 2006 | Hinton提出深度信念网络                                       | Hinton, G. E., Osindero, S., & Teh, Y. W. (2006). A fast learning algorithm for deep belief nets. Neural computation, 18(7), 1527-1554 |
| 2008 | 采用DBNs来完成回归任务                                       | Hinton, G. E., & Salakhutdinov, R. R. (2008). Using deep belief nets to learn covariance kernels for Gaussian processes. In Advances in neural information processing systems (pp. 1249-1256) |
| 2009 | 将卷积深度信念网络用于可视物体识别                           | Lee, H., Grosse, R., Ranganath, R., & Ng, A. Y. (2009, June). Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In Proceedings of the 26th annual international conference on machine learning (pp. 609-616). ACM |
| 2012 | DBNs应用在语音识别领域                                       | Mohamed, A. R., Dahl, G. E., & Hinton, G. (2012). Acoustic modeling using deep belief networks. IEEE Transactions on Audio, Speech, and Language Processing, 20(1), 14-22 |
| 2014 | Goodfellow提出生成对抗网络                                   | Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., ... & Bengio, Y. (2014). Generative adversarial nets. In Advances in neural information processing systems (pp. 2672-2680) |
| 2016 | Deepmind创建了一个深度 生成模型Wavenet，可用来 生成具有自然人声的语音 | Van Den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., ... & Kavukcuoglu, K. (2016). Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499 |

# Hopfield神经网络

神经网络可以分为，多层神经网络和相互连接型网络。

- 多层神经网络：模式识别
- 相互连接型网络：通过联想记忆去除数据中的噪声

<img src="./PIC/11/11.3.png" alt="11.3" style="zoom:50%;" />

1982年提出的 Hopfield 神经网络是最典型的相互连结型网络。













# 玻尔兹曼机和受限玻尔兹曼机







# 深度玻尔兹曼机和深度信念网络

深度玻尔兹曼机(Deep Boltzmann Machine, DBM) 是由受限玻尔兹曼机堆叠组成。

深度信念网络(Deep Belief Network, DBN)：最上面的两层之间有无方向的对称连接，形成联想记忆。下层从上层接收自上而下的定向连接。最底层单元的状态表示一个数据向量。

<img src="./PIC/11/11.4.png" alt="11.4" style="zoom:50%;" />

参考论文：

[1] Hinton, Geoffrey E., Simon Osindero, and Yee-Whye Teh. "A fast learning algorithm for deep belief nets." Neural computation 18, no. 7 (2006): 1527-1554.
[2] Hinton GE. Deep belief networks. Scholarpedia. 2009 May 31;4(5):5947.

深度玻尔兹曼机采用与多层神经网络不同的训练方法，在训练时采用对比散度算法，逐层来调整连接权重和偏置。

具体做法：

- 首先训练输入层和隐藏层之间的参数，把训练后得到的参数作为下一层的输入
- 再调整该层与下一个隐藏层之间的参数
- 然后逐次迭代，完成多层网络的训练

<img src="./PIC/11/11.5.png" alt="11.5" style="zoom:50%;" />

深度玻尔兹曼机既可以当作生成模型，也可以当作判别模型

- 作为生成模型使用时，网络会按照某种概率分布生成训练数据。概 率分布可根据训练样本导出，但是覆盖全部数据模式的概率分布很难导出，所以通常选择最大似然估计法训练参数，得到最能覆盖训练样本的概率分布

  这种生成模型能够：去除输入数据中含有的噪声，得到新的数据， 对输入数据压缩和特征表达

- 作为判别模型使用时，需要在模型顶层添加一层Softmax实现分类

  进行分类时，需要同时提供训练样本和期望输出，在最顶层级联一 个𝑆𝑜𝑓𝑡𝑚𝑎𝑥层

训练方法：

- 除最顶层外，其他各层都可以使用无监督学习进行训练。
- 把训练得到的参数作为初始值，使用误差反向传播算法对包含最顶 层的神经网络进行训练
- 最顶层的参数使用随机数进行初始化

# 自编码器及其变种

自编码器(Autoencoder):是一种有效的数据维度压缩算法， 主要应用在以下两个方面：

- 构建一种能够重构输入样本并进行特征表达的神经网络
  - 特征表达：是指对于分类会发生变动的不稳定模式，例如手写字体识 别中由于不同人的书写习惯和风格的不同造成字符模式不稳定，或者输入样本中包含噪声等情况，神经网络也能将其转换成可以准确识别的特征。

- 训练多层神经网络时，通过自编码器训练样本得到参数初始值





























