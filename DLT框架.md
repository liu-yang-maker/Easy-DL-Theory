#### 项目初衷

近些年，以机器学习为代表的人工智能技术逐渐被大家认识并在很多方面得到普及，深度学习技术在学术界和工业界取得了广泛的成功，受到高度重视，并掀起新一轮的人工智能热潮。我们希望通过组队学习的方式，让大家更清楚的了解深度学习的理论。

本课程讲授和讨论深度学习的主要理论和关键技术，主要内容有深度学习基础、卷积神经网络、循环神经网络、深度生成模型、深度学习正则化等以及上述深度学习理论在图像、语音、自然语言处理等领域的主要应用，同时也介绍了一些新兴的深度学习模型及其应用。

通过本课程的学习，希望能够掌握深度学习的基本理论和关键技术，提高基于深度学习技术进行科学研究与应用开发的能力。

学习的先修要求：了解一些基本的机器学习算法和高数知识，不要求编程，只讲述理论。

#### 内容设置

课程内容计划分成两个阶段：

深度学习理论入门：主要介绍深度学习的基本背景和数学基础，主要介绍CNN和RNN的相关知识。

深度学习理论进阶：在第一部分的基础上延伸对神经网络的理解，并介绍一些常见的优化算法和正则化方法，以及现在很流行的注意力机制，以及深度生成模型。

案例：主要介绍深度学习的主要平台，和深度学习在CV、Speech和NLP方面的应用。

------



1. 绪论与深度学习概述
   1. 人工智能、机器学习与深度学习
   2. 起源与发展
   3. 重要的研究机构和著名科学家
   4. 定义、理论和方法
   5. 主要应用
2. 数学基础
   1. 张量、矩阵运算、矩阵的基础知识、矩阵分解
   2. 概率统计、常见的（多变量）分布
   3. 信息论、熵、互信息、相对熵、交叉熵
   4. 最优化估计方法、最小二乘、线性模型
3. 机器学习基础
   1. 数据集
   2. 误差分析
   3. 代表的机器学习方法
      1. 有监督、线性回归、SVM、决策树、RF
      2. 无监督、聚类、降维（PCA）
4. 前馈神经网络 
   1. 神经元模型
   2. 感知器、多层感知器
   3. BP算法
   4. 前馈神经网络
5. 卷积神经网络CNN 
   1. 卷积
   2. CNN基本原理
   3. 经典CNN
   4. CNN主要应用
6. 循环神经网络RNN
   1. 计算图
   2. RNN
   3. 长短时记忆网络
   4. 其他RNN
   5. RNN主要应用



1. 网络优化
2. 正则化方法
3. 注意力机制与外部记忆
   1. 注意力机制
   2. 记忆网络
4. Transformer 模型
   1. BERT
   2. GPT
5. 深度生成模型
   1. 深度生成模型概述
   2. Hopfield 神经网络
   3. 玻尔兹曼机和受限玻尔兹曼机
   4. 深度信念网络
   5. 自编码器
   6. 生成对抗网络



1. 深度学习常见的平台
   1. Tensorflow
   2. PyTorch
   3. Keras
   4. PaddlePaddle
   5. MindSpore
2. CV图像
   1. 图像/视频处理
   2. 图像/视频压缩
   3. 图像分类
   4. 目标检测
   5. 图像分割
   6. 图像回归
3. Speech语音
   1. 语音数据集
   2. 语音识别
   3. 声纹识别
   4. 语音合成
4. NLP自然语言处理
   1. 语言模型
   2. 机器翻译
   3. 机器阅读理解
   4. 自动摘要
   5. 图像描述
5. 中英文对照手册



#### 人员安排

| 成员   | 个人简介                                            | 个人主页 |
| ------ | --------------------------------------------------- | -------- |
| 刘洋   | DataWhale成员，中国科学院数学与系统科学研究院研究生 |          |
| 李嘉骐 | DataWhale成员，清华大学自动化系研究生               |          |

#### 其他

















